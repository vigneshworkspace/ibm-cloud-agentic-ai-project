{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Agents Lab Notebook v1.0.0\n",
    "This notebook contains steps and code to demonstrate the use of agents\n",
    "configured in Agent Lab in watsonx.ai. It introduces Python API commands\n",
    "for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n",
    "\n",
    "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
    "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
    "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Notebook goals\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
    "* Creating an agent with a set of tools using a specified model and parameters\n",
    "* Invoking the agent to generate a response \n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_ibm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import dependencies\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_ibm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatWatsonx\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mibm_watsonx_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m APIClient\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIMessage, HumanMessage\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_ibm'"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
    "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def get_credentials():\n",
    "\treturn {\n",
    "\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
    "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    "\t}\n",
    "\n",
    "def get_bearer_token():\n",
    "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "credentials = get_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the agent\n",
    "These cells demonstrate how to create and invoke the agent\n",
    "with the selected models, tools, and parameters.\n",
    "\n",
    "## Defining the model id\n",
    "We need to specify model id that will be used for inferencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/mistral-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the\n",
    "result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the project id or space id\n",
    "The API requires project id or space id that provides the context for the call. We will obtain\n",
    "the id from the project or space in which this notebook runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the agent\n",
    "We need to create the agent using the properties we defined so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n",
    "\n",
    "# Create the chat model\n",
    "def create_chat_model():\n",
    "    chat_model = ChatWatsonx(\n",
    "        model_id=model_id,\n",
    "        url=credentials[\"url\"],\n",
    "        space_id=space_id,\n",
    "        project_id=project_id,\n",
    "        params=parameters,\n",
    "        watsonx_client=client,\n",
    "    )\n",
    "    return chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=client)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
    "    from langchain_core.tools import StructuredTool\n",
    "    utility_agent_tool = Toolkit(\n",
    "        api_client=api_client\n",
    "    ).get_tool(tool_name)\n",
    "\n",
    "    tool_description = utility_agent_tool.get(\"description\")\n",
    "\n",
    "    if (kwargs.get(\"tool_description\")):\n",
    "        tool_description = kwargs.get(\"tool_description\")\n",
    "    elif (utility_agent_tool.get(\"agent_description\")):\n",
    "        tool_description = utility_agent_tool.get(\"agent_description\")\n",
    "    \n",
    "    tool_schema = utility_agent_tool.get(\"input_schema\")\n",
    "    if (tool_schema == None):\n",
    "        tool_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "            \"properties\": {\n",
    "                \"input\": {\n",
    "                    \"description\": \"input for the tool\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def run_tool(**tool_input):\n",
    "        query = tool_input\n",
    "        if (utility_agent_tool.get(\"input_schema\") == None):\n",
    "            query = tool_input.get(\"input\")\n",
    "\n",
    "        results = utility_agent_tool.run(\n",
    "            input=query,\n",
    "            config=params\n",
    "        )\n",
    "        \n",
    "        return results.get(\"output\")\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=tool_name,\n",
    "        description = tool_description,\n",
    "        func=run_tool,\n",
    "        args_schema=tool_schema\n",
    "    )\n",
    "\n",
    "\n",
    "def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
    "    from langchain_core.tools import StructuredTool\n",
    "    import ast\n",
    "\n",
    "    def call_tool(**kwargs):\n",
    "        tree = ast.parse(tool_code, mode=\"exec\")\n",
    "        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
    "        function_name = custom_tool_functions[0].name\n",
    "        compiled_code = compile(tree, 'custom_tool', 'exec')\n",
    "        namespace = tool_params if tool_params else {}\n",
    "        exec(compiled_code, namespace)\n",
    "        return namespace[function_name](**kwargs)\n",
    "        \n",
    "    tool = StructuredTool(\n",
    "        name=tool_name,\n",
    "        description = tool_description,\n",
    "        func=call_tool,\n",
    "        args_schema=tool_schema\n",
    "    )\n",
    "    return tool\n",
    "\n",
    "def create_custom_tools():\n",
    "    custom_tools = []\n",
    "\n",
    "\n",
    "def create_tools(context):\n",
    "    tools = []\n",
    "    \n",
    "    config = None\n",
    "    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"Weather\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n",
    "    config = {\n",
    "        \"maxResults\": 5\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n",
    "\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(context):\n",
    "    # Initialize the agent\n",
    "    chat_model = create_chat_model()\n",
    "    tools = create_tools(context)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    instructions = \"\"\"# Notes\n",
    "- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n",
    "- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\n",
    "You are a Travel Planner AI Agent designed to assist users in planning personalized and efficient trips. Your task is to understand user preferences (such as destination, travel dates, budget, and interests) and generate tailored travel itineraries using real-time data and intelligent reasoning.\n",
    "\n",
    "You have access to the following tools:\n",
    "- Google Search: Use to retrieve general travel information, location highlights, tourist attractions, accommodations, and news.\n",
    "- DuckDuckGo Search: Use as an alternative search engine for broader or privacy-focused queries.\n",
    "- Wikipedia Search: Use to retrieve factual summaries of cities, attractions, landmarks, or cultural information.\n",
    "- Webcrawler: Use to extract specific information from user-provided URLs (e.g., event schedules, booking sites).\n",
    "- Weather: Use to retrieve weather forecasts for specific cities and dates, helping you tailor activities based on climate conditions.\n",
    "\n",
    "Goals:\n",
    "1. Extract user preferences through natural conversation.\n",
    "2. Use tools strategically to gather relevant and up-to-date information.\n",
    "3. Construct a daily itinerary based on user goals, timing, location logistics, and conditions.\n",
    "4. Recommend alternatives if conflicts arise (e.g., bad weather, closed locations).\n",
    "5. Communicate clearly and helpfully, asking only necessary follow-up questions.\n",
    "\n",
    "Behavior Guidelines:\n",
    "- Plan step-by-step: identify destination, gather relevant data, optimize schedule.\n",
    "- When providing options (e.g., places to visit), suggest only 3–5 top recommendations unless asked for more.\n",
    "- Consider travel time and group similar activities logically in the day plan.\n",
    "- Adapt recommendations based on weather forecasts or event data if available.\n",
    "- Do not make bookings unless explicitly instructed.\n",
    "\n",
    "Output Format:\n",
    "- Trip Summary: Based on user's input (dates, destination, goals).\n",
    "- Daily Itinerary: Morning, afternoon, evening plan with activities and travel suggestions.\n",
    "- Additional Notes: Weather info, flexibility tips, or important advisories.\n",
    "\n",
    "Tone:\n",
    "- Friendly, professional, and informative.\n",
    "- Avoid overloading the user with data—summarize when possible.\n",
    "- If uncertain, use search tools to verify information before responding.\n",
    "\n",
    "Limitations:\n",
    "- Do not store or recall user data across sessions.\n",
    "- Avoid giving financial advice or making speculative predictions.\n",
    "\n",
    "Always strive to create a smooth and enjoyable travel planning experience using the tools and information at your disposal.\n",
    "\"\"\"\n",
    "\n",
    "    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "Image(\n",
    "    create_agent(context).get_graph().draw_mermaid_png(\n",
    "        draw_method=MermaidDrawMethod.API,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the agent\n",
    "Let us now use the created agent, pair it with the input, and generate the response to your question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(context)\n",
    "\n",
    "def convert_messages(messages):\n",
    "    converted_messages = []\n",
    "    for message in messages:\n",
    "        if (message[\"role\"] == \"user\"):\n",
    "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "        elif (message[\"role\"] == \"assistant\"):\n",
    "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "    return converted_messages\n",
    "\n",
    "question = input(\"Question: \")\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": question\n",
    "}]\n",
    "\n",
    "generated_response = agent.invoke(\n",
    "    { \"messages\": convert_messages(messages) },\n",
    "    { \"configurable\": { \"thread_id\": \"42\" } }\n",
    ")\n",
    "\n",
    "print_full_response = False\n",
    "\n",
    "if (print_full_response):\n",
    "    print(generated_response)\n",
    "else:\n",
    "    result = generated_response[\"messages\"][-1].content\n",
    "    print(f\"Agent: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "You successfully completed this notebook! You learned how to use\n",
    "watsonx.ai inferencing SDK to generate response from the foundation model\n",
    "based on the provided input, model id and model parameters. Check out the\n",
    "official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n",
    "\n",
    "<a id=\"copyrights\"></a>\n",
    "### Copyrights\n",
    "\n",
    "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
    "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
